// src/services/openaiService.ts
import OpenAI from "openai";
import type { ChatCompletionMessageParam } from "openai/resources/chat/completions";
import dotenv from "dotenv";
import { safeJSON } from "../utils/safeJSON"; // ajusta el path si es necesario

dotenv.config();
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });

/* ---------- Tipos de plan de lectura/escritura ---------- */
export type FindStep = {
  mode: "find";
  collection: string;
  filter?: Record<string, any>;
  projection?: Record<string, 0 | 1>;
  limit?: number;
  sort?: Record<string, 1 | -1>;
  skip?: number;
};

export type AggregateStep = {
  mode: "aggregate";
  collection: string;
  pipeline: any[];
};

export type ReadPlan =
  | FindStep
  | AggregateStep
  | { steps: Array<FindStep | AggregateStep> };

export type WriteOp =
  | {
      action: "insertOne" | "insertMany";
      collection: string;
      data: Record<string, any> | Record<string, any>[];
      options?: Record<string, any>;
    }
  | {
      action: "updateOne" | "updateMany";
      collection: string;
      filter: Record<string, any>;
      update: Record<string, any>;
      options?: Record<string, any>;
    }
  | {
      action: "deleteOne" | "deleteMany";
      collection: string;
      filter: Record<string, any>;
      options?: Record<string, any>;
    }
  | { action: "none" };

/* ---------- Helpers ---------- */
const isComparisonRequest = (question: string): boolean => {
  const lower = question.toLowerCase();
  return (
    lower.includes("comparar") ||
    lower.includes("comparaci√≥n") ||
    lower.includes("cu√°l es mejor") ||
    lower.includes("mejor precio") ||
    lower.includes("m√°s conveniente") ||
    lower.includes(" vs ") ||
    lower.includes("versus")
  );
};

/* ---------- Prompts ---------- */
const comparisonPrompt = `
Sos un experto en compras. Tu tarea es **comparar cotizaciones entre proveedores** y mostrarlo con claridad.

üßæ Instrucciones:
1. Identific√° los productos cotizados por cada proveedor.
2. Arm√° una tabla exacta en Markdown:

| √çtem | Proveedor A | Proveedor B | Selecci√≥n |
|------|-------------|-------------|-----------|

- ‚Äú√çtem‚Äù: nombre del producto o referencia.
- ‚ÄúProveedor A‚Äù y ‚ÄúProveedor B‚Äù: precio cotizado.
- ‚ÄúSelecci√≥n‚Äù: cu√°l es mejor y por qu√© (ej: ‚ÄúProveedor A (por mejor precio)‚Äù).
- Si un proveedor no cotiz√≥, pon√© ‚Äú-‚Äù.

3. Si hay m√°s de dos proveedores, agreg√° columnas adicionales.
4. Al final, una conclusi√≥n breve del criterio de elecci√≥n.

‚ö†Ô∏è Si no hay datos suficientes, devolv√© **‚ÄúNo hay suficientes datos para hacer una comparaci√≥n.‚Äù**
`;

const NATURAL_PROMPT = (question: string, data: any) => `
Eres un asistente que responde consultas sobre nuestra base de datos de construcci√≥n.

1. Comienza con una frase natural (‚ÄúClaro, esto es lo que encontr√©:‚Äù, etc).
2. Presenta los datos recibidos en \`data\`:
   - Si vienen objetos simples, haz una lista.
   - Si son objetos con m√∫ltiples campos, haz una tabla en Markdown.
3. Al final, secci√≥n **Entidades detectadas:** con badges en l√≠nea ‚Üí \`[tipo: valor]\`.
4. Si no hay resultados, ‚ÄúLo siento, no encontr√© resultados para esa consulta.‚Äù

Consulta:
\`\`\`
${question}
\`\`\`

Datos JSON:
\`\`\`json
${JSON.stringify(data, null, 2)}
\`\`\`
`;

const READ_PROMPT = (question: string) => `
Sos un generador de consultas para MongoDB.
Tu salida debe ser **EXCLUSIVAMENTE** un JSON v√°lido (sin backticks ni texto extra).

... aqu√≠ va el resto de tu prompt de lectura ...

Pregunta del usuario:
"${question}"
`;

const WRITE_PROMPT = (question: string) => `
Sos un generador de planes de escritura para MongoDB.
Tu √∫nica tarea es devolver un JSON v√°lido con una instrucci√≥n de escritura.

... aqu√≠ va el resto de tu prompt de escritura ...

Consulta del usuario:
"${question}"
`;

/* ---------- Funciones ---------- */
export const getMongoQuery = async (question: string): Promise<ReadPlan> => {
  const resp = await openai.chat.completions.create({
    model: "gpt-3.5-turbo",
    temperature: 0,
    top_p: 0,
    messages: [{ role: "user", content: READ_PROMPT(question) }],
  });
  return safeJSON<ReadPlan>(resp.choices[0].message.content || "");
};

export const getMongoWriteOp = async (question: string): Promise<WriteOp> => {
  const resp = await openai.chat.completions.create({
    model: "gpt-3.5-turbo",
    temperature: 0,
    top_p: 0,
    messages: [{ role: "user", content: WRITE_PROMPT(question) }],
  });
  return safeJSON<WriteOp>(resp.choices[0].message.content || "");
};

export const getNaturalAnswer = async (
  question: string,
  data: any
): Promise<string> => {
  const cmp = isComparisonRequest(question);

 const messages: ChatCompletionMessageParam[] = cmp
  ? [
      { role: "system", content: comparisonPrompt },
      {
        role: "user",
        content: `Datos JSON:\n\`\`\`json\n${JSON.stringify(data, null, 2)}\n\`\`\``,
      },
    ]
  : [
      {
        role: "system",
        content: NATURAL_PROMPT(question, data),
      },
    ];
  const resp = await openai.chat.completions.create({
    model: "gpt-4o",
    temperature: 0,
    messages,
  });

  return resp.choices[0].message.content?.trim() || "No se pudo generar una respuesta.";
};
